{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ghh2W-w1BKoL",
        "XQjoZ4D1MEBS",
        "5Tm9Cp0CBGGT",
        "Z5FWXy-CBWzL",
        "h-TU0bbR67uF",
        "5H82lzjs6tpi",
        "QimiajKh4tDV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ファインチューニングの実験 \n",
        "\n",
        "## 事前学習済みモデル \n",
        "rinna社の日本語GPT-2 [1, 2] (**japanese-gpt2-medium** [3]) を用いる.  \n",
        "3.36億パラメータ, 24層のモデルで, 学習にはメモリ32GBのV100を8台で45日を要したとある.\n",
        "\n",
        "## データセット \n",
        "**おーぷん2ちゃんねる対話コーパス** [4, 5] を用いる (こちら [6] で知った).  \n",
        "およそ約815万件の対話データを収録. 無償で商用利用も可.  \n",
        "このうち, `newsplus.tsv` の前から1万件のみを用いる. \n"
      ],
      "metadata": {
        "id": "T4NWgidssIZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 準備 \n"
      ],
      "metadata": {
        "id": "Ghh2W-w1BKoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUの確認\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "WNwk_c9gzJyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パッケージのインストール\n",
        "!git clone https://github.com/huggingface/transformers -b v4.23.1\n",
        "!pip install transformers==4.23.1\n",
        "!pip install evaluate==0.3.0\n",
        "!pip install sentencepiece==0.1.97\n"
      ],
      "metadata": {
        "id": "Nyys_S29zWLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Googleドライブの作業フォルダ「work」の作成 \n"
      ],
      "metadata": {
        "id": "XQjoZ4D1MEBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "!mkdir -p \"/content/drive/MyDrive/work\"\n",
        "%cd \"/content/drive/MyDrive/work\"\n"
      ],
      "metadata": {
        "id": "HgcSpFPALOrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 前処理 \n",
        "\n",
        "あらかじめ `dir_name` 以下に, コーパスのデータを置いておく. \n"
      ],
      "metadata": {
        "id": "5Tm9Cp0CBGGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "# このディレクトリにデータを置いておく\n",
        "dir_name = \"data/open2ch-dialogue-corpus/corpus\"\n",
        "\n",
        "def preprocess(input_file_name, output_file_name, max_n_lines=None, output_mode=\"w\"):\n",
        "  \"\"\"\n",
        "  前処理では, \n",
        "   ・ 改行記号「 __BR__ 」が1つ〜3つ連続の場合, 半角空白1つへ置換\n",
        "   ・ タブ記号を半角空白1つへ置換\n",
        "\n",
        "  前処理した結果をファイルへ書込み. output_modeに従う\n",
        "   ・ 既定値: \"w\" (上書きモード)\n",
        "   ・ \"a\" (追記モード)\n",
        "  \"\"\"\n",
        "\n",
        "  input_file_path = os.path.join(dir_name, input_file_name)\n",
        "  output_file_path = os.path.join(dir_name, output_file_name)\n",
        "\n",
        "  texts = []\n",
        "  print_steps = 10000  # 何件ごとに進捗を表示するか\n",
        "  with open(input_file_path) as f:\n",
        "    for i, l in enumerate(f):\n",
        "\n",
        "      # 最大行数が指定されていて, かつ, それに達したら終了\n",
        "      if max_n_lines is not None and max_n_lines <= i:\n",
        "        break\n",
        "\n",
        "      # 改行記号は「 __BR__ 」へ置換されている. これを半角空白1つへ置換する\n",
        "      l = re.sub(\" __BR__ __BR__ __BR__ \", \" \", l)  # 3つ連続の場合\n",
        "      l = re.sub(\" __BR__ __BR__ \", \" \", l)  # 2つ連続の場合\n",
        "      l = re.sub(\" __BR__ \", \" \", l)  # 1つの場合\n",
        "\n",
        "      # レスアンカー「>>」はタブ記号へ置換されている. これを半角空白1つへ置換する\n",
        "      l = re.sub(\"\\t\", \" \", l)\n",
        "\n",
        "      texts.append(l)\n",
        "\n",
        "      # 何件かごとに進捗を表示\n",
        "      if (i+1) % print_steps == 0:\n",
        "        print(f\"{i+1:9,} 件 Done!\")\n",
        "\n",
        "  # 書込み\n",
        "  with open(output_file_path, output_mode) as f:\n",
        "    f.writelines(texts)\n",
        "\n",
        "  return output_file_path\n"
      ],
      "metadata": {
        "id": "l3aF1C271nmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "\"\"\"\n",
        "コーパスには3つのファイルがある\n",
        " ・ livejupiter.tsv (5,948,218 行)\n",
        " ・ news4vip.tsv (1,983,626 行)\n",
        " ・ newsplus.tsv (217,296 行)\n",
        "\"\"\"\n",
        "DATA_NAME = \"newsplus\"  # 学習データ名\n",
        "DATA_SIZE = 1  # 学習データに何「万」件用いるか\n",
        "\n",
        "input_file_name = f\"{DATA_NAME}.tsv\"\n",
        "output_file_name = f\"preprocessed_{DATA_NAME}.txt\"\n",
        "\n",
        "output_file_path = preprocess(\n",
        "    input_file_name, output_file_name, max_n_lines=DATA_SIZE*10000, output_mode=\"w\")\n",
        "\n",
        "print(f\"\\n前処理済みテキストファイルのパスは, \\n\\t{output_file_path}\\nです. \\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJCB4Gk_g_UU",
        "outputId": "0383afe8-8e21-425b-e431-f89a8ced979a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   10,000 件 Done!\n",
            "\n",
            "前処理済みテキストファイルのパスは, \n",
            "\tdata/open2ch-dialogue-corpus/corpus/preprocessed_newsplus.txt\n",
            "です. \n",
            "\n",
            "CPU times: user 100 ms, sys: 13.3 ms, total: 113 ms\n",
            "Wall time: 548 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習 \n",
        "\n",
        "* `--model_name_or_path` に, 事前学習済みモデルのパスを指定. \n",
        "* `--train_file` と `--validation_file` の両方に, 前処理済みテキストファイルのパスを指定. \n",
        "\n",
        "モデルが `rinna/japanese-gpt2-medium` の場合, \n",
        "* `--per_device_train_batch_size` に `1` を指定しないと, メモリ不足で学習できなかった. \n",
        "* `--per_device_eval_batch_size` は `8` が限界だった. \n"
      ],
      "metadata": {
        "id": "Z5FWXy-CBWzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!python /content/transformers/examples/pytorch/language-modeling/run_clm.py \\\n",
        "    --model_name_or_path=rinna/japanese-gpt2-medium \\\n",
        "    --train_file=data/open2ch-dialogue-corpus/corpus/preprocessed_newsplus.txt \\\n",
        "    --validation_file=data/open2ch-dialogue-corpus/corpus/preprocessed_newsplus.txt \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --num_train_epochs=2 \\\n",
        "    --save_steps=100 \\\n",
        "    --save_total_limit=3 \\\n",
        "    --per_device_train_batch_size=1 \\\n",
        "    --per_device_eval_batch_size=8 \\\n",
        "    --output_dir=output/ \\\n",
        "    --overwrite_output_dir=true\n"
      ],
      "metadata": {
        "id": "2R5blh_C0Nri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ファインチューニング後の推論結果 "
      ],
      "metadata": {
        "id": "h-TU0bbR67uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "INPUT_TEXT = \"ww\"  # 入力するテキスト\n",
        "\n",
        "\n",
        "def print_result(result):\n",
        "  \"\"\"\n",
        "  結果を整理して表示\n",
        "  \"\"\"\n",
        "\n",
        "  for i, l in enumerate(result):\n",
        "    print(f\"\\n◆ {i+1}番めの結果: \\n{l}\\n\")\n"
      ],
      "metadata": {
        "id": "pfYe9c5g0Oiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"output/\")\n"
      ],
      "metadata": {
        "id": "DJNRCqZzb8NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "output = model.generate(\n",
        "    tokenizer.encode(INPUT_TEXT, return_tensors=\"pt\"), \n",
        "    do_sample=True, max_length=100, num_return_sequences=8\n",
        ")\n",
        "\n",
        "# 結果を整理して表示\n",
        "print_result(tokenizer.batch_decode(output, skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "MIwCvqcw0O6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ファインチューニング前の推論結果 \n"
      ],
      "metadata": {
        "id": "5H82lzjs6tpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt2-medium\")\n"
      ],
      "metadata": {
        "id": "YTcmsGn50PA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "output = model.generate(\n",
        "    tokenizer.encode(INPUT_TEXT, return_tensors=\"pt\"), \n",
        "    do_sample=True, max_length=100, num_return_sequences=8\n",
        ")\n",
        "\n",
        "# 結果を整理して表示\n",
        "print_result(tokenizer.batch_decode(output, skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "7BNcdHrw0PF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 参考 \n",
        "\n",
        "1. rinnakk, \"japanese-pretrained-models\", GitHub.  \n",
        "  https://github.com/rinnakk/japanese-pretrained-models \n",
        "\n",
        "2. 趙 天雨, 沢田 慶, \"日本語自然言語処理における事前学習モデルの公開\", 人工知能学会研究会資料 言語・音声理解と対話処理研究会, vol.93, pp.169-170, 2021. \n",
        "\n",
        "3. rinna, \"japanese-gpt2-medium\", Hugging Face.  \n",
        "  https://huggingface.co/rinna/japanese-gpt2-medium \n",
        "\n",
        "4. 1never, \"おーぷん2ちゃんねる対話コーパス\", GitHub.  \n",
        "  https://github.com/1never/open2ch-dialogue-corpus \n",
        "\n",
        "5. 稲葉 通将, \"おーぷん2ちゃんねる対話コーパスを用いた用例ベース対話システム\", 第87回言語・音声理解と対話処理研究会(第10回対話システムシンポジウム), 人工知能学会研究会資料 SIG-SLUD-B902-33, pp.129-132, 2019. \n",
        "\n",
        "6. 水上 雅博, 吉野 幸一郎, 中野 幹生, 赤間 怜奈, 駒谷 和範, 吉川 禎洋, 林部 祐太, 児玉 貴志, \"日本語対話コーパス\".  \n",
        "  https://masahiro-mi.github.io/dialogue_corpus.html \n",
        "\n"
      ],
      "metadata": {
        "id": "QimiajKh4tDV"
      }
    }
  ]
}